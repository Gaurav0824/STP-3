{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2f226088f9aa54435886bc4e07e709ff8ae133f9654d81ad46d3f29751b53116"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "mysocket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "mysocket.connect(('www.google.com',80))\n",
    "cmd = 'GET http://www.bing.com/   HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysocket.send(cmd)\n",
    "while True:\n",
    "    data = mysocket.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(encoding='utf-8'),end='\\n')\n",
    "mysocket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser in 4 lines\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "# url = \"http://www.python.org/\"\n",
    "url = \"http://www.bing.com/\"\n",
    "\n",
    "html = urllib.request.urlopen(url)\n",
    "data = html.read()\n",
    "print(data.decode()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(data,'html.parser')\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# url = \"http://www.python.org/\"\n",
    "url = \"http://www.bing.com/\"\n",
    "\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "j=0\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))\n",
    "    j+=1\n",
    "    if j >= 18:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "search = input(\"Enter Search Terms : \")\n",
    "if search:\n",
    "    params = {\"q\": search}\n",
    "    r = requests.get(\"http://www.bing.com/search\", params=params)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    results = soup.find(\"ol\", {\"id\": \"b_results\"})\n",
    "    links = results.findAll(\"li\", {\"class\": \"b_algo\"})\n",
    "    for item in links:\n",
    "        item_text = item.find(\"a\").text\n",
    "        item_href = item.find(\"a\").attrs[\"href\"]\n",
    "        if item_href or item_text:\n",
    "            print(item_href)\n",
    "            print(item_text)\n",
    "            print(\"Summary : \", item.find(\"a\").parent.parent.find(\"p\").text)\n",
    "            children = item.children\n",
    "            for child in children:\n",
    "                print(\"Child : \", child.text[:80])\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "api_key = 42\n",
    "# Ignore SSL certificate errors...............\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    \n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "        break\n",
    "    \n",
    "    print(json.dumps(js, indent=4))    "
   ]
  },
  {
   "source": [
    "    TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'\n",
    "    USER_URL = 'https://api.twitter.com/1.1/users/lookup.json'"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "APP_ROOT = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "conn = sqlite3.connect(APP_ROOT+'\\\\test.sqlite')\n",
    "cur = conn.cursor()\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS People\n",
    "                                (id                 INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                                name           TEXT UNIQUE,\n",
    "                                data             TEXT DEFAULT NULL,\n",
    "                                retrieved    INTEGER  DEFAULT (0) CHECK (retrieved in (0,1) ) )''')\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1', (acct, ))\n",
    "id = cur.fetchone()[0]"
   ]
  }
 ]
}